secion.names=c("Politics","Economy","Society","Life","World","IT")
#헤더라인 5개를 각 카테로기 별로 입력하는 데이터 프레임을 만듭니다.
news.head=data.frame(head_1=c(1:6),head_2=NA,head_3=NA,head_4=NA,head_5=NA)
# row name을 카테고리 명칭으로 변경(추출하는 csv에서 첫 번째 열에 나타나도록 합니다.)
rownames(news.head)=secion.names
for(i in 1:ncol(news.head)){ # 현재 6행이므로 6번 반복
findNum=paste0(".num",i)  # 헤드라인마다 번호가 다르므로 번호를 바꿀 수 있도록 합니다.
nodeValue=html_nodes(news,findNum) #class가 6개 이므로 node 6개여야 합니다.
for(j in 1:nrow(news.head)){  # 정치~it 까지의 카테고리에 대한 for 문
# gsub()로 데이터표현을 바꿉니다. "\t" -> "" 로 바꿉니다.
extracted.head=gsub("\t","",nodeValue[j]%>%html_text())%>%strsplit("\n")
trim.head=trimws(extracted.head[[1]])   # 글자 앞뒤의 빈공간을 엾애줍니다.
selected.head=trim.head[-which(trim.head=="")]   # 공란으로 된 character를 제외한 나머지를 찾습니다.
if(selected.head[1]=="동영상기사"){  # 가끔 동영상 기사의 경우, 헤드보다 앞에 표시가 되도록 합니다.
news.head[j,i]=selected.head[2]
}
else{
news.head[j,i]=selected.head[1]
}
}
}
news.head
write.csv(news.head,"popularNewsHeadlines.csv",row.names=T)
news.head
library(lubridate)
setDate<-ymd("2019-07-30")-days(0:365)
setDate<-format(setDate,"%Y%m%d")
setDate
setDate<-ymd("2019-07-30")-days(0:365)
setDate<-format(setDate,"%Y%m%d")
for(d in 1:length(setDate)){
urlNews<-paste0("https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&date=",setDate[d])
newsData<-read_html(urlNews)
sectionName<-c("Policy","Economy","Society","Life","World","It")
newsHead=data.frame(head_1=c(1:6),head_2=NA,head_3=NA,head_4=NA,head_5=NA)
rownames(newsHead)<-sectionName
for(i in 1:(ncol(newsHead))){
findNum<-paste0(".num",i)
nodeValue<-html_nodes(newsData,findNum)
for(j in 1:nrow(newsHead)){
extractHead<-gsub("\t","",nodeValue[j] %>% html_text()) %>% strsplit("\n")
trimHead<-trimws(extractHead[[1]])
selectHead<-trimHead[-which(trimHead=="")]
if(selectHead[1]=="동영상기사"){
newsHead[j,i]<-selectHead[2]
}
else{
newsHead[j,i]<-selectHead[1]
}
}
}
write.csv(newsHead,paste0("poopularNewsHeadlines(",setDate[d],").csv"))
}
page<-read_html(url,encoding='euc-kr')
url<-"https://finance.naver.com/item/board.nhn?code=005930&page=1"
page<-read_html(url,encoding='euc-kr')
page2<-html_nodes(page,'td.title a')
page3<-html_attr(page2,'title')
page4<-as.data.frame(page3)
page4
url<-"https://finance.naver.com/item/board.nhn?code=005930&page=1"
page<-read_html(url,encoding='euc-kr')
page2<-html_nodes(page,'td.title a')
page3<-html_attr(page2,'title')
page4<-as.data.frame(page3)
page4
page5<-list()
for(i in 1:10){
url<-paste("https://finance.naver.com/item/board.nhn?code=005930&page=",i,sep='')
page5[[i]]<-read_html(url,encoding='euc-kr') %>% html_nodes("td.title a") %>% html_attr('title')
}
page5
write.csv(unlist(page5),'ddt.csv')
install.packages("KoNLP")
install_github("SukjaeChoi/RHINO")
.libPaths()
library(rJava)
library(KoNLP)
library(RHINO)
library(devtools)
library(stringr)
library(wordcloud)
library(RCurl)
library(rvest)
library(dplyr)
library(xml2)
library(lubridate)
setwd("D:/BigDataCampus/practiceData")
data1<-readLines("경주여행_지식인_2016.txt")
Encoding(data1)<-"UTF-8"
#head(data1,10)
length(data1)
data1<-unique(data1)
data2<-str_replace_all(data1,"[^[:alpha:][:digit:]]"," ")
data3<-extractNoun(data2)
#head(data3,5)
data4<-lapply(data3,unique)
data5<-gsub("\\d+","",unlist(data4))
data5<-gsub("스프링","스프링돔",data5)
data5<-gsub("파크","워터파크",data5)
data5<-gsub("\\^","",data5)
data5<-gsub(paste(c("교촌","마을","한옥"),collapse="|"),"교촌한옥마을",data5)
data5<-gsub(paste(c("주상","절리"),collapse="|"),"주상절리",data5)
data5<-gsub(paste(c("보문단지","보문"),collapse="|"),"보문관광단지",data5)
data5<-gsub(paste(c("달동네","추억","추억의달동네"),collapse="|"),"추억의달동네",data5)
data5<-gsub(paste(c("한우","떡갈비"),collapse='|'),"한우수제떡갈비",data5)
data5<-gsub(paste(c("게스트","하우스"),collapse="|"),"게스트하우스",data5)
data5<-gsub(paste(c("월성","반월성"),collapse='|'),"반월성",data5)
data5<-gsub(paste(c("맛집이","맛집"),collapse='|'),"맛집",data5)
data5<-gsub(paste(c("교리","김밥","계란지단"),collapse="|"),"교리김밥",data5)
data5<-gsub(paste(c("천마","천마총"),collapse="|"),"천마총",data5)
data5<-gsub(paste(c("박물관","테디베어","테디베어박물관"),collapse="|"),"테디베어박물관",data5)
data5<-gsub("월드","월드엑스포",data5)
data5<-gsub("순두부","멧돌순두부",data5)
data5<-gsub(paste(c("현대","밀면"),collapse="|"),"현대밀면",data5)
data5<-gsub("한정","이조한정식",data5)
data5<-gsub("블루","블루원워터파크",data5)
data5<-lapply(data5,unique)
data6<-sapply(data5,function(x){Filter(function(y){nchar(y) <= 6 & nchar(y)>1},x)})
wordcount<-table(unlist(data6))
wordcount<-Filter(function(x){nchar(x)<=10},wordcount)
head(sort(wordcount,decreasing=T),100)
txt<-readLines("경주여행_지식인_2016.txt")
cnt_txt<-length(txt)
cnt_txt
data5<-gsub((txt[i]),"",data5)
for ( i in 1:cnt_txt){
data5<-gsub((txt[i]),"",data5)
}
txt<-readLines("경주여행_지식인_2016.txt")
cnt_txt<-length(txt)
cnt_txt
for ( i in 1:cnt_txt){
data5<-gsub((txt[i]),"",data5)
}
head(data5,5)
for ( i in 1:cnt_txt){
data5<-gsub((txt[i]),"",data5)
}
data5<-gsub((txt[i]),'',data5)
for ( i in 1:cnt_txt){
data5<-gsub(txt[i],'',data5)
}
data6<-sapply(data5,function(x){Filter(function(y){nchar(y)>=2},x)})
head(data6,5)
wordcount<-table(unlist(data6))
head(sort(wordcount,decreasing=T),100)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
#install.packages("RColorBrewer")
palete<-brewer.pal(7,"Set2")
#install.packages("RColorBrewer")
library(RColorBrewer)
palete<-brewer.pal(7,"Set2")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
#install.packages("RColorBrewer")
library(RColorBrewer)
palete<-brewer.pal(7,"Set2")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
install.packages(tm)
install.packages("tm")
#install.packages("tm")
library(tm)
palete<-brewer.pal(7,"Set2")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
library(wordcloud)
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
palete<-brewer.pal(7,"Set2")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
wordcount<-table(unlist(data6))
data54<-head(sort(wordcount,decreasing = T),100)
write.table(data54,"data54.txt")
data64<-read.table("data54.txt")
col4<-ifelse(data64$Freq>=100,"red","gray")
wordcloud(data64$Var1,freq = data64$Freq.scale=c(4,1),rot.per=0.25,min.freq=1,random.order=F,ordered.color=T,colors=col4)
wordcloud(data64$Var1,freq = data64$Freq,scale=c(4,1),rot.per=0.25,min.freq=1,random.order=F,ordered.color=T,colors=col4)
install.packages("wordcloud2")
library(wordcloud2)
wordcount2<-head(sort(wordcount,decreasing = T),100)
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="Alice")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
length(data1)
# txt파일의 글자가 깨지므로, Encoding(data1)
data1<-readLines("경주여행_지식인_2016.txt")
Encoding(data1)<-"UTF-8"
length(data1)
head(data1)
data1<-unique(data1)
head(data1)
data2<-str_replace_all(data1,"[^[:alpha:][:digit:]]"," ")
library(stringr)
data2<-str_replace_all(data1,"[^[:alpha:][:digit:]]"," ")
data3<-extractNoun(data2)
library(rJava)
library(RCurl)
library(rvest)
library(dplyr)
library(xml2)
library(lubridate)
library(KoNLP)
library(RHINO)
library(devtools)
library(stringr)
library(wordcloud)
library(RColorBrewer)
library(tm)
library(wordcloud2)
data3<-extractNoun(data2)
?Filter
# data6의 빈도수를 만듭니다.
wordcount<-table(unlist(data6))
wordcount
txt<-readLines("경주여행_지식인_2016.txt")
cnt_txt<-length(txt)
cnt_txt
for ( i in 1:cnt_txt){
data5<-gsub((txt[i]),'',data5)
}
for ( i in 1:cnt_txt){
data5<-gsub("(txt[i])",'',data5)
}
head(data5,5)
data6<-sapply(data5,function(x){Filter(function(y){nchar(y)>=2},x)})
head(data6,5)
wordcount<-table(unlist(data6))
head(sort(wordcount,decreasing=T),100)
palete<-brewer.pal(7,"Set2")
wordcloud(names(wordcount),freq=wordcount,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color=T,colors=palete)
wordcount<-table(unlist(data6))
data54<-head(sort(wordcount,decreasing = T),100)
data64<-read.table("data54.txt")
col4<-ifelse(data64$Freq>=100,"red","gray")
wordcloud(data64$Var1,freq = data64$Freq,scale=c(4,1),rot.per=0.25,min.freq=1,random.order=F,ordered.color=T,colors=col4)
wordcount2<-head(sort(wordcount,decreasing = T),100)
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
data('crude')
summary(crude)
inspect(crude[1])
length(crude)
crude[[1]]$content
crude[[1]]$meta
meta(crude[[1]],tag="author")<-'홍길동'
meta(crude[[1]],tag="2nd author")<-'홍길자'
crude[[1]]$meta
crude_lower<-tm_map(crude,tolower)
inspect(crude_lower[1])
crude_lower[[1]]
install.packages("SnowallC")
crude_stemDocumnet<-tm_map(crude,stemDocument)
# install.packages("SnowallC")
library(SnowallC)
install.packages("SnowallC")
library(SnowallC)
install.packages("SnowballC")
library(SnowballC)
crude_stemDocumnet<-tm_map(crude,stemDocument)
crude_stemDocumnet[[1]]$content
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:\BigDataCampus")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:/BigDataCampus")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 100,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1000,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 10000,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcount2<-head(sort(wordcount,decreasing = T),100)
wordcloud2(wordcount2,gridSize = 10000,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 10000,size=1000,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 10000,size=10000,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 10000,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(wordcount2,gridSize = 10000,size=100,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath = "D:/BigDataCampus/cloud_img.jpg")
?wordcloud2()
?wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpeg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2,gridSize = 1,size=0.5,figPath="D:/BigDataCampus/cloud_img.jpg")
wordcount2<-head(sort(wordcount,decreasing = T),100)
wordcount2
demoFreq
wordcloud2(wordcount2, figPath="D:/BigDataCampus/cloud_img.jpg")
wordcloud2(wordcount2, figPath="D:/BigDataCampus/cloud_img.jpg")
str(demoFreq)
str(wordcount2)
wordcloud2(demoFreq, figPath="D:/BigDataCampus/cloud_img.jpg")
="
wordcloud2(demoFreq, figPath="D:/BigDataCampus/cloud_img.jpg")
as.data.frame(wordcount2)
wordcloud2(demoFreq, figPath="D:/BigDataCampus/cloud_img.jpg")
library(wordcloud2)
wordcloud2(demoFreq, figPath = "cloud_img.jpg")
wordcloud2(demoFreq, figPath="D:/BigDataCampus/cloud_img.jpg")
show<-wordcloud2(demoFreq, figPath="D:/BigDataCampus/cloud_img.jpg")
View(show)#-------------------------------------------------------------------------------------------------
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(demoFreq, figPath = "cloud_img.jpg")
wordcloud2(demoFreq, figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq, figPath = "D:/BigDataCampus/cloud_img.jpg")
wordcloud2(demoFreq,gridSize = 1,size=0.5,shape="star")
wordcloud2(demoFreq,gridSize = 1,size=0.5,shape="cloud_img.jpg")
img.jpg"
wordcloud2(demoFreq,gridSize = 1,size=0.5,shape="cloud_img.jpg",figPath ="D:/BigDataCampus/cloud_img.jpg" )
wordcloud2(demoFreq,gridSize = 1,size=0.5,figPath ="D:/BigDataCampus/cloud_img.jpg" )
?wordcloud2
wordcloud2(demoFreq,size=2)
?wordcloud2
wordcloud2(demoFreq,size=2,shape='circle')
?wordcloud2
head(demoFreq)
head(wordcount2)
as.data.frame(wordcount2)
head(wordcount2)
wordcount2<-as.data.frame(wordcount2)
head(wordcount2)
wordcloud2(wordcount2,size=2,figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcloud2(wordcount2,size=2,figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcloud2(wordcount2,gridSize=1,size=0.5,figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcloud2(wordcount2,gridSize=1,size=0.5,backgroundColor = "grey",figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcloud2(wordcount2,gridSize=1,size=0.5,backgroundColor = "gray",figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(demoFreq,gridSize = 1,size=0.5,figPath ="D:/BigDataCampus/cloud_img.jpg" )
wordcloud2(wordcount2,gridSize=1,size=0.5,backgroundColor = "gray",figPath = "D:/BigDataCampus/cloud_img.jpg",)
wordcount2<-head(sort(wordcount,decreasing = T),100)
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star",word="R")
wordcloud2(wordcount2,word="R",gridSize = 1,size=0.5,shape="star")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="R")
letterCloud(wordcount2,word="R",gridSize=1,size=0.5)
letterCloud(wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="R")
wordcloud2(demoFreq,gridSize = 1,size=0.5,figPath ="D:/BigDataCampus/cloud_img.jpg" )
letterCloud(data=wordcount2,word="R",wordSize = 1,fontFamily="나눔바른고딕",color="random-light")
wordcloud2(wordcount2,gridSize = 1,size=0.5,shape="star")
hiphop <- read.table("hiphop.txt", sep="\n")
hiphop <- readLines("hiphop.txt")
hiphop
noun <- lapply(hiphop, extractNoun)
noun
unlist(noun)
initRhino
initRhino()
noun <- lapply(hiphop, getMorph, 'noun')
nounVec <- unlist(noun)
nounFreq <- table(nounVec)
head(sort(nounFreq, decreasing = T), 20)
#단어만 추출
word <- names(head(sort(nounFreq, decreasing = T), 20))
word
#빈도만 추출
freq <- as.vector(head(sort(nounFreq, decreasing = T), 20))
freq
sum <- sum(nounFreq)
sum
percent <- round(freq/sum*100, digits = 2)
mainTxt <- "고빈도 단어"
mainTxt
bp <- barplot(percent, main = mainTxt, las = 2 , ylim = c(0 , 20), ylab = "%",
names.arg = word, col="black")
text(x=bp, y=percent+0.1, labels = paste(freq), col="black", cex=0.8)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=28,
random.order = F,random.color=T,colors=palete)
# 연습문제
hiphop <- read.table("hiphop.txt", sep="\n")
hiphop <- readLines("hiphop.txt")
noun <- lapply(hiphop, extractNoun)
unlist(noun)
initRhino()
noun <- lapply(hiphop, getMorph, 'noun')
nounVec <- unlist(noun)
nounFreq <- table(nounVec)
head(sort(nounFreq, decreasing = T), 20)
#단어만 추출
word <- names(head(sort(nounFreq, decreasing = T), 20))
#빈도만 추출
freq <- as.vector(head(sort(nounFreq, decreasing = T), 20))
sum <- sum(nounFreq)
percent <- round(freq/sum*100, digits = 2)
mainTxt <- "고빈도 단어"
bp <- barplot(percent, main = mainTxt, las = 2 , ylim = c(0 , 20), ylab = "%",
names.arg = word, col="black")
text(x=bp, y=percent+0.1, labels = paste(freq), col="black", cex=0.8)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=28,
random.order = F,random.color=T,colors=palete)
hiphop
noun
data<-unique(noun)
data
data1<-unique(noun)
data2<-sapply(data1,function(x){Filter(function(y){nchar(y)<=6 & nchar(y)>1},x)})
data2
nounFreq<-table(data2)
data2<-unlist(data2)
data2
nounFreq<-table(data2)
word<-names(head(sort(nounFreq,decreasing = T),20))
freq<-as.vector(head(sort(nounFreq,decreasing = T),20))
sum<-sum(nounFreq)
percent<-round(freq/sum*100,digits=2)
mainTxt<-"고빈도 단어"
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color = T,colors=palete)
wordcloud(word,freq,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=28,random.order = F,random.color = T,colors=palete)
freq<-as.vector(head(sort(nounFreq,decreasing = T),20))
freq
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.025,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=0.5,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=0.5,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=0.25,min.freq=0.01,random.order = F,random.color = T,colors=palete)
freq
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=1,min.freq=0.01,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=1,min.freq=28,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=1,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=10,min.freq=1,random.order = F,random.color = T,colors=palete)
wordcloud(names(nounFreq),freq=nounFreq,scale=c(5,1),rot.per=1,min.freq=1,random.order = F,random.color = T,colors=palete)
data('crude')
summary(crude)
inspect(crude[[1]])
crude[[1]]
crude[[1]]$content
meta(crude[[1]],tag="author")<-"홍길동"
meta(crude[[1]],tag="2nd author")<-"홍길자"
crude[[1]]$meta
meta(crude[[1]],tag="author")<-"홍길동"
meta(crude[[1]],tag="2nd author")<-"홍길자"
crude[[1]]$meta
crude_lower<-tm_map(crude,tolower)
inspect(crude_lower[1])
crude_lower[[1]]
crude_lower[[1]]$meta
crude_lower[[1]]
crude_stemDocumnet<-tm_map(crude,stemDocument)
crude_stemDocumnet[[1]]$content
crude_stripWhitespace<-tm_map(crude,stripWhitespace)
crude_stripWhitespace[[1]]$content
crude_removePunctuation<-tm_map(crude,removePunctuation)
crude_removePunctuation[[1]]$content
crude_removeNumbers<-tm_map(crude,removeNumbers)
crude_removeNumbers[[1]]$content
# 단어를 제거합니다.
crude_removeWord<-tm_map(crude,removeWords,"Diamond")
crude_removeWord[[1]]$content
crude_removeWord<-tm_map(crude,removeWords,stopwords("english"))
crude_removeWord[[1]]$content
# 최대한 문서 안에서 텍스트 전처리를 실시해야 합니다. !!!
crude_lower<-tm_map(crude,tolower)
crude_clean<-tm_map(crude_lower,PlainTextDocument)
crude_clean[[1]]$content
crude_clean[[1]]$meta
data("crude")
dtm<-DocumentTermMatrix(crude)
inspect(dtm)
inspect(dtm[1:10,1:5])
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfidf))
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfIdf()))
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfIdf)
inspect(dtm2[1:10,1:5])
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfIdf)
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfIdf))
dtm2<-DocumentTermMatrix(crude,control=list(weighting=weightTfIdf))
inspect(dtm2[1:10,1:5])
dtm<-DocumentTermMatrix(crude)
findFreqTerms(dtm,lowfreq=10)
f<-findAssocs(dtm,"oil",0.7)
f$oil
class(dtm
)
dtm.mx<-as.matrix(dtm)
class(dtm.mx)
dtm.df<-as.data.frame(dtm.mx)
dtm.label.df<-cbind(dtm.df,LAVEL=c(rep("crude",length(crude))))
head(dtm.label.df[,c(1260:1267)])
data("crude"); data("acq")
crude_acq<-c(DocumentTermMatrix(crude),DocumentTermMatrix(acq))
crude_acq_df<-cbind(as.data.frame(as.matrix(crude_acq)),LABEL=c(rep("crude",length(crude)),rep("acq",length(acq))))
head(crude_acq_df[,c(1:5,length(crude_acq_df))])
to_dtm<-function(corpus){
x<-tm_map(corpus,removePunctuation)
x<-tm_map(x,removeWords,stopwords())
return(DocumentTermMatrix(x))
}
crude_acq<-c(to_dtm(crude),to_dtm(acq))
crude_acq_df<-cbind(as.data.frame(as.matrix(crude_acq)),LABEL=c(rep("crude",length(crude)),rep("acq",length(acq))))
head(crude_acq_df[,c(1:5,length(crude_acq_df))])
crude_acq<-c(to_dtm(crude),to_dtm(acq))
crude_acq_df<-cbind(as.data.frame(as.matrix(crude_acq)),LABEL=c(rep("crude",length(crude)),
rep("acq",length(acq))))
head(crude_acq_df[,c(1:5,length(crude_acq_df))])
crude_acq_df<-cbind(as.data.frame(as.matrix(crude_acq)),
LABEL=c(rep("crude",length(crude)),rep("acq",length(acq))))
head(crude_acq_df[,c(1:5,length(crude_acq_df))])
